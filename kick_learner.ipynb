{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74311715-4288-40c4-a5c6-3ac13502535b",
   "metadata": {},
   "source": [
    "# CST 383 – Intro to Data Science\n",
    "### Project 2: Predicting Kickstarter Goal Completion\n",
    "**Authors:** Brianna Magallon, Tyler Pruitt, Rafael L.S. Reis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2abba3-2cd9-4a21-813e-fd78cb95fe0f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this project, we use the Kickstarter Projects dataset to build a model that predicts whether a crowdfunding campaign will succeed or fail based on information available at launch. Each entry includes metadata such as goal amount, number of backers, campaign duration, and category.\n",
    "\n",
    "We treat this as a binary classification problem, where the outcomes are `'successful'` or `'failed'`. We merge `'canceled'` campaigns into the `'failed'` category, based on the observation that they typically don't meet funding goals.\n",
    "\n",
    "**Dataset Source:**  \n",
    "[Kickstarter Projects (Kaggle)](https://www.kaggle.com/datasets/kemical/kickstarter-projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ada490-50ed-49cf-99eb-e767383a42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df41d9-1efa-4332-8516-966ae178cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid', context='notebook')\n",
    "plt.rcParams['figure.figsize'] = 5,3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af77e08-130d-44c9-9590-dc50fb5a6ce0",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb5270-0a9f-4d67-807e-f389e7df1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ks-projects-201612.csv\", encoding=\"cp1252\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548f04a-2c7c-4cbc-9e9e-809ccdaae018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a2a5b-a615-41c6-910c-d9d18c15ad98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b439c3-efa8-43a7-bb1f-c939f0f8bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e5aee9-f2c7-4888-ac26-62e95616c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['state'] == \"canceled\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cee829-fe12-4b82-b1a9-254b3f2c70dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad09da-56d1-4f57-a242-9add6b1236ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = df[df['country'] == 'US']\n",
    "dftest = dftest.drop(columns=[\"Unnamed: 13\", \"Unnamed: 14\", \"Unnamed: 15\", \"Unnamed: 16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c7056-ab7e-4404-b3fd-f60e49ad6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b0d8bd-13a1-463e-a932-ace93e51841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest['main_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba501279-17cb-4478-8984-50a9411b2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_counts = df['state'].value_counts().head(10)\n",
    "state_counts.plot.bar()\n",
    "plt.title('Distribution of campaign outcomes')\n",
    "plt.xlabel('state')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526f7df-5bb7-45f8-95c8-6217cdfd76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['main_category'].value_counts().head(10).plot.bar()\n",
    "plt.title(\"Number of campaigns per main category\")\n",
    "plt.xlabel(\"main category \")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac4ae0",
   "metadata": {},
   "source": [
    "## Data Cleaning & Preprocessing\n",
    "\n",
    "We begin cleaning by dropping empty or irrelevant columns and filtering to U.S.-based projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aad55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 13\", \"Unnamed: 14\", \"Unnamed: 15\", \"Unnamed: 16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64196cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['state'].isin([\"successful\", \"failed\", \"canceled\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows still with null values: \", len(df[df.isnull().any(axis=1)]))\n",
    "df[df.isnull().any(axis=1)].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7664962b-c4a0-4552-8b19-0082361c9089",
   "metadata": {},
   "source": [
    "The majority of rows with null values are music or film projects with 0 backers and questionable labels. There's probably a starving artist joke somewhere in there. These rows are minimal (~127), so we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b55760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "len(df[df.isnull().any(axis=1)])  # confirm\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab041fd-58eb-412f-8b48-80a5f6a18cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['backers'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c6c316-f8fc-45c3-8aba-abab6e6316a1",
   "metadata": {},
   "source": [
    "We now correct numeric fields and focus on U.S. projects. Some columns have numeric values stored as strings, so we convert them. This helps avoid bugs later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcb0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['goal'] = pd.to_numeric(df['goal'], errors='coerce').astype(int)\n",
    "df.dropna(subset=['goal'], inplace=True)\n",
    "print(df['goal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59388a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['country'] == 'US']\n",
    "df = df.drop(columns=[\"usd pledged\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea53398-c7c3-416e-819d-c75cf705fda7",
   "metadata": {},
   "source": [
    "We convert string dates to datetime, compute duration, and encode labels for our classification model. We also merge `canceled` with `failed`, since both don't meet funding goals — canceled ones just end early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0f4e7-657f-4830-8deb-d58331aac0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['launched'] = pd.to_datetime(df['launched'])\n",
    "df['deadline'] = pd.to_datetime(df['deadline'])\n",
    "df['duration_days'] = (df['deadline'] - df['launched']).dt.days\n",
    "\n",
    "df['state'] = df['state'].replace('canceled', 'failed')\n",
    "df = df[df['state'].isin(['failed', 'successful'])].copy()\n",
    "df['state_encoded'] = df['state'].map({'failed': 1, 'successful': 0})\n",
    "\n",
    "numeric_cols = ['goal', 'pledged', 'backers', 'pledged']\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "df = df.drop(columns=['ID', 'name', 'deadline', 'state', 'country', 'currency','pledged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3b068-1dfc-41ef-bf87-03bc48068b6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b877de1-deb8-4df8-9e8c-df061d7cca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4754090d-6e90-41cb-9fc0-d3de97538f6b",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "We define our features and target, then apply a baseline and two models. We'll compare their performance to understand how well basic models do on this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['goal', 'backers', 'pledged', 'duration_days']]\n",
    "y = df['state_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "baseline = DummyClassifier(strategy='most_frequent')\n",
    "baseline.fit(X_train, y_train)\n",
    "y_pred_baseline = baseline.predict(X_test)\n",
    "print(\"Baseline accuracy:\", accuracy_score(y_test, y_pred_baseline))\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "print(\"Logistic Regression accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"KNN accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6193e4-a3ba-4376-954a-77115c9be761",
   "metadata": {},
   "source": [
    "Both models beat the baseline, but KNN appears to be overfitting. More work is needed to improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6100870d-06d2-4682-ab3a-bb7b2e7731f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(logreg, X_test, y_test)\n",
    "plt.title(\"Logistic Regression - Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(knn, X_test, y_test)\n",
    "plt.title(\"KNN - Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee97224-e313-44f5-bd12-0081c5b4c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.Series(logreg.coef_[0], index=X.columns)\n",
    "coeffs.sort_values().plot(kind='barh')\n",
    "plt.title(\"Logistic Regression Feature Coefficients\")\n",
    "plt.xlabel(\"Impact on 'Failure' Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f36ba-65d0-4bd3-b651-b47f5efbf48f",
   "metadata": {},
   "source": [
    "The feature coefficients are helpful for interpretation. Backers and pledged amount seem to be the strongest predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82920c3-7e01-446b-ad57-e05b7c80f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['backers']).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6c3a7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project demonstrates the potential of using simple machine learning models to predict Kickstarter campaign outcomes based on basic project metadata. While we achieved accuracy improvements over a baseline dummy classifier, the models are still far from production-ready.\n",
    "\n",
    "We found that:\n",
    "- **Logistic Regression** provided reasonable performance and interpretable coefficients, highlighting the importance of features like number of backers and pledged amount.\n",
    "- **K-Nearest Neighbors** appeared to overfit the training data, performing well on training but less effectively on the test set.\n",
    "- Both models, while better than guessing the majority class, still left substantial room for improvement.\n",
    "\n",
    "### Challenges & Next Steps:\n",
    "- The overfitting observed, especially in KNN, suggests a need for perhaps **feature scaling**, **regularization**, or **simplification**.\n",
    "- We haven’t yet made use of potentially informative categorical features like main_category or category.\n",
    "- Adding **cross-validation**, **feature engineering**, and testing other models (e.g., decision trees, gradient boosting) would be valuable next steps.\n",
    "\n",
    "While this was a solid start, there’s still a lot of work ahead to build a robust and generalizable model. That said, we're excited to dive into model tuning and optimization since this is the part we all find most engaging. The data cleaning process was a bit frustrating and a bit of a pain sometimes... so we're glad to have made it through that and can now focus on the fun side of machine learning :)\n",
    "\n",
    "\n",
    "\n",
    "(I know we might do some more cleaning stuff, but we're mostly done with that)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
